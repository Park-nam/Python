{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcad785",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation\n",
    "\n",
    "- 모든 데이터셋을 Train에 활용할 수 있음\n",
    "- 정확도를 향상시킬 수 있으며 데이터 부족으로 인한 과소적합을 방지할 수 있다.\n",
    "\n",
    "- 모든 데이터셋을 validation에 활용할 수 있음.\n",
    "- 평가에 사용되는 데이터 편중을 막을 수 있으며 결과에 따라 더 일반화된 모델을 구축할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9ad51",
   "metadata": {},
   "source": [
    "Train set / Valid set / Test set -> K-fold cross validation\n",
    "- valid set은 Train set으로 부터 추출한다\n",
    "- n개의 폴드 세트로부터 추출된 예측 평가는 평균해서 평가 결과에 반영하면 된다.\n",
    "\n",
    "#### ------------Train set -------------------------------------------------------------------------------------------------Test set--------------\n",
    "\n",
    "- split 1    Fold 1   Fold 2   Fold 3   Fold 4   Fold 5  --->  Fold 1(valid) / 나머지 학습(Train) ---> prediction(split 1)\n",
    "- split 2    Fold 1   Fold 2   Fold 3   Fold 4   Fold 5  --->  Fold 2(valid) / 나머지 학습(Train) ---> prediction(split 2)\n",
    "- split 3    Fold 1   Fold 2   Fold 3   Fold 4   Fold 5  --->  Fold 3(valid) / 나머지 학습(Train) ---> prediction(split 3)\n",
    "- split 4    Fold 1   Fold 2   Fold 3   Fold 4   Fold 5  --->  Fold 4(valid) / 나머지 학습(Train) ---> prediction(split 4)\n",
    "- split 5    Fold 1   Fold 2   Fold 3   Fold 4   Fold 5  --->  Fold 5(valid) / 나머지 학습(Train) ---> prediction(split 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f92750",
   "metadata": {},
   "source": [
    "# 1. K-Fold\n",
    "\n",
    "- sklearn.model_selection의 KFold 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1852327",
   "metadata": {},
   "source": [
    "- Decisiontreeclassifier를 iris데이터 적용 후 교차검증 실시\n",
    "- 의사결정나무에 대해서는 추후 자세히 다룸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d385f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붗꽃 데이터 세트 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 의사결정나무 모델 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold=KFold(n_splits=5)    # n_splits의 default 값은 5\n",
    "cv_accuracy = []\n",
    "print('붗꽃 데이터 세트 크기 :', X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c15b05",
   "metadata": {},
   "source": [
    "- 데이터의 크기가 150개이기 때문에 학습용(train)은 120개, 검증용(valid)은 30개로 분할된다.\n",
    "- kfold의 split() 메서드를 사용해 학습용(train)/검증용(valid) 데이터를 분할한다.\n",
    "- split() 메서드를 사용한 데이터 추출은 반환된 인덱스 기반으로 수행해야 한다.\n",
    "      -> 폴드 별 학습용, 검증용 데스트의 로우 인덱스를 array로 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2970c60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 1 교차 검증 정확도:1.0, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "\n",
      "# 1 검증 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "# 2 교차 검증 정확도:0.9667, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "\n",
      "# 2 검증 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "# 3 교차 검증 정확도:0.8667, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "\n",
      "# 3 검증 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "# 4 교차 검증 정확도:0.9333, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "\n",
      "# 4 검증 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "# 5 교차 검증 정확도:0.7333, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "\n",
      "# 5 검증 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# kfold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 데스트의 로우 인덱스를 array로 반환한다.\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    # kfold.spli()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터를 추출한다.\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    n_iter+=1\n",
    "    # 반복 시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)                # accuracy_score(실제값, 모델 출력값)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n# {0} 교차 검증 정확도:{1}, 학습데이터 크기:{2}, 검증데이터 크기:{3}'.format(n_iter,accuracy,train_size,test_size))\n",
    "    print('\\n# {0} 검증 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n## 평균 검증 정확도:',np.round(np.mean(cv_accuracy),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446deb46",
   "metadata": {},
   "source": [
    "# 2. Stratified K-Fold\n",
    "- 분류에 적용한다.\n",
    "- 불균형한 분포도를 가진 레이블(종속변수) 데이터 집합을 위한 k폴드 방식(이는 곧 한쪽으로 치우친 분포를 의미한다)\n",
    "- 위와 같이 불균형한 분포는 학습/검증 데이터 집합에 균등하게 배분되지 못하는 문제가 발생하는데 stratified k폴드는 이를 해결해 줌\n",
    "- sklearn.model_selection의 StratifiedKFold 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556659b9",
   "metadata": {},
   "source": [
    "### 먼저 k-fold를 사용해 발생 가능한 문제를 확인하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447f8090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris=load_iris()\n",
    "iris_df = pd.DataFrame(iris, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2483e6",
   "metadata": {},
   "source": [
    "### 아래 결과를 보면 학습/검증용으로 분할된 데이터는 각 다른 속성을 갖기 때문에 예측에 전혀 이용될 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc7015cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 교차검증 : 1\n",
      "----------------------------------------\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "## 교차검증 : 2\n",
      "----------------------------------------\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "## 교차검증 : 3\n",
      "----------------------------------------\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3개의 폴드를 생성 후 교차 검증시 생성되는 학습/검증 레이블 데이터 값의 분포도 확인\n",
    "\n",
    "kfold=KFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter +=1\n",
    "    label_train = iris_df.label.iloc[train_index]\n",
    "    label_test = iris_df.label.iloc[test_index]\n",
    "    print('\\n## 교차검증 : {0}'.format(n_iter))\n",
    "    print('-'*40)\n",
    "    print('학습 레이블 데이터 분포:\\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711419d",
   "metadata": {},
   "source": [
    "### 이제 Stratified K-Fold를 적용하여 문제를 해결해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a52dab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증 :0\n",
      "학습 레이블 데이터 분포 :\n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 :\n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차검증 :0\n",
      "학습 레이블 데이터 분포 :\n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 :\n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차검증 :0\n",
      "학습 레이블 데이터 분포 :\n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포 :\n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df.label):\n",
    "    label_train=iris_df.label.iloc[train_index]\n",
    "    label_test=iris_df.label.iloc[test_index]\n",
    "    print('## 교차검증 :{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 :\\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포 :\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305d392",
   "metadata": {},
   "source": [
    "### Stratified K-Fold를 적용한 데이터 분리와 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1921d299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 교차 검증 정확도:0.98, 학습 데이터 크기:100, 검증 데이터 크기:50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "#2 교차 검증 정확도:0.94, 학습 데이터 크기:100, 검증 데이터 크기:50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "#3 교차 검증 정확도:0.98, 학습 데이터 크기:100, 검증 데이터 크기:50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\\m## 교차 검증별 정확도 : [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도 : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "df_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFold는 split() 호출 시 반드시 종속변수 데이터 세트도 같이 입력해야 한다.\n",
    "for train_index, test_index in skfold.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # 학습 및 예측\n",
    "    df_clf.fit(X_train, y_train)\n",
    "    pred = df_clf.predict(X_test)\n",
    "    \n",
    "    # 반복 시마다 정확도 측정\n",
    "    n_iter +=1\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('#{0} 교차 검증 정확도:{1}, 학습 데이터 크기:{2}, 검증 데이터 크기:{3}'.format(n_iter,accuracy,train_size,test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 교차 검증별 정확도 및 평균 정확도 계산\n",
    "print('\\m## 교차 검증별 정확도 :', np.round(cv_accuracy,4))\n",
    "print('## 평균 검증 정확도 :', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8306bb7",
   "metadata": {},
   "source": [
    "# 3. cross_val_score()\n",
    "- KFold에서 fold 세트를 설정하고 데이터를 분핳하여 예측을 통한 성능 반환을 한번에 수행하는 API\n",
    "- cross_val_score(estimator, X, y, scoring, cv, ...)\n",
    "- startified k 폴드 방식으로 데이터를 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9750d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 : [0.98 0.94 0.98]\n",
      "평균 검증 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "iris=load_iris()\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "# 성능 지표는 accurancy, 교차 검증 세트는 3개\n",
    "score=cross_val_score(dt_clf,X,y,scoring='accuracy',cv=3)\n",
    "print('교차 검증별 정확도 : {0}'.format(score))\n",
    "print('평균 검증 정확도 :', np.round(np.mean(score),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2152423",
   "metadata": {},
   "source": [
    "# 4. cross_validate()\n",
    "- cross_val_score()가 하나의 평가 지표만 사용 가능하지만, cross_validate()는 여러 개의 평가지표를 사용할 수 있다.\n",
    "- 또한 성능 평가 지표와 수행 시간도 함께 제공한다.\n",
    "\n",
    "- cross_validate(estimator, X, y, scoring=[], cv= , ...)\n",
    "- scoring에 MSE나 MAE는 앞에 neg_를 붙인다.\n",
    "- 딕셔너리 형태로 출력됨\n",
    "\n",
    "\n",
    "- 결과값 확인\n",
    "             \n",
    "      - 적합 수행 시간 : x['fit_time']\n",
    "      - 지표 수행 시간 : x['score_time']\n",
    "      - 각 지표 출력값 : x['test_평가지표']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8559d379",
   "metadata": {},
   "source": [
    "# 5. GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에\n",
    "- sklearn.model_selection의 GridSearchCV 클래스 사용\n",
    "- 회귀나 분류 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터 도출\n",
    "- for 반복문을 좀 더 간편하게 사용하기 위해 제공되는 알고리즘\n",
    "- 교차 검증을 기반으로 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11243a",
   "metadata": {},
   "source": [
    "- GridSearchCV(estimator, param_grid, scoring, cv, refit=True(default), verbose)\n",
    "      -> estimator : classifier, regressor, pipeline\n",
    "      -> param_grid : key + 리스트 값을 갖는 딕셔너리. estimator 튜닝을 위해 파라미터명과 사용될 여러 파라미터값 지정\n",
    "      -> refit : 최적 하이퍼 파라미터를 찾은 후 estimator에 재학습\n",
    "      -> GridSearchCV의 verbose : iteration시마다 수행 결과 메시지를 출력합니다.\n",
    "         1) verbose=0(default)면 메시지 출력 안함\n",
    "         2) verbose=1이면 간단한 메시지 출력\n",
    "         3) verbose=2이면 하이퍼 파라미터별 메시지 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9cdc8",
   "metadata": {},
   "source": [
    "- 의사결정나무 알고리즘을 적용하는 하이퍼 파라미터 튜닝(해당 하이퍼 파라미터 : max_depth, min_samples_split)\n",
    "- 하이퍼 파라미터 세트 : 딕셔너리 타입\n",
    "- 하이퍼 파라미터 명칭 : 문자열 key 값\n",
    "- 하이퍼 파라미터의 값 : 리스트 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f18c3",
   "metadata": {},
   "source": [
    "- best_params_ : GridSearchCV가 튜닝한 최적 파라미터\n",
    "- best_score_ : GridSearchCV가 튜닝한 최적 파라미터를 사용했을 경우 정확도\n",
    "- best_estimator_ : GridSearchCV가 튜닝한 최적 파라미터\n",
    "- cv_results : GridSearchCV가 출력한 값을 반환. 일반적으로 데이터프레임 함수를 적용하여 반환한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4acb2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리 형태로 설정\n",
    "parameter = {'max_depth':[1,2,3],'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e33f381",
   "metadata": {},
   "source": [
    "- gridsearchcv 객체의 fit 메서드를 수행하면 학습 데이터를 cv에 기술된 폴딩 세트로 분할\n",
    "- 이후 param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가를 수행하고 그 결과를 cv_results_속성에 기록\n",
    "- cv_results_는 gridsearchcv의 결과 세트로서 딕셔너리 형태로 key 값과 리스트 형태의 value 값을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c17d5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_grid의 하이퍼 파라미터를 3개의 fold로 나누어 테스트 수행\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameter, cv=3, refit=True)\n",
    "\n",
    "# iris 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# gridsearchcv 결과를 추출해 dataframe으로 변환\n",
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "score_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e954d6e",
   "metadata": {},
   "source": [
    "- max_depth : 3, min_samples_split : 2  => 하이퍼 파라미터 최적의 값\n",
    "- params : 수행할 때마다 적용된 개별 하이퍼 파라미터 값\n",
    "- rank_test_score : 하이퍼 파라미터별로 성능이 좋은 score 순위를 나타냄. 1이 가장 우수한 순위이며 이때의 파라미터가 최적의 파라미터\n",
    "- mean_test_score : 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값(높을수록 우수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f81ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.975\n"
     ]
    }
   ],
   "source": [
    "# best_params_ / best_score_\n",
    "print('GridSearchCV 최적 파라미터 :', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도 :', grid_dtree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aefc6e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy :0.9667\n"
     ]
    }
   ],
   "source": [
    "# 최적 성능을 나타내고 있는 하이퍼 파라미터를 저장한 후 test_data에 적용한다.\n",
    "\n",
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학스비 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('Test set accuracy :{0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc608cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
